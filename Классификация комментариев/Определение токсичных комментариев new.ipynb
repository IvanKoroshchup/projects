{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проект для «Викишоп»\n",
    "\n",
    "### Задача"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, то есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучим модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Импортируем необходимые библиотеки\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from pymystem3 import Mystem\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Загружаем файл с данными\n",
    "data = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Лемматизируем текст (время исполнения ячейки 2,5 минуты)\n",
    "m = Mystem()\n",
    "def token_text (row):\n",
    "    category = m.lemmatize(row)\n",
    "    row = ''.join(category)\n",
    "    return row.rstrip('\\n')\n",
    "#data['tokenized']= data['text'].apply(token_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Explanation Why the edits made under my userna...\n",
       "1    D aww He matches this background colour I m se...\n",
       "2    Hey man I m really not trying to edit war It s...\n",
       "3    More I can t make any real suggestions on impr...\n",
       "4    You sir are my hero Any chance you remember wh...\n",
       "Name: clean_text, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Очистим данные от лишних символов\n",
    "def clear (row):\n",
    "    w = re.sub(r'[^a-zA-Z]',' ',row)\n",
    "    n = \" \".join(w.split())\n",
    "    return n\n",
    "data['clean_text']= data['text'].apply(clear)\n",
    "display(data['clean_text'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Создадим счетчик слов tfid idf, указав стоп слова, для очистки текста\n",
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords, lowercase=True, min_df=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Обозначим признаки и таргет\n",
    "features = data['clean_text']\n",
    "target = data['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Разделим данные на обучающую и тестовую выборки в соотношении 95/5\n",
    "features_train, features_test, target_train,target_test = train_test_split(features, target, test_size = 0.05, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Переведем подготовленный текст в формат unicode\n",
    "features_train = features_train.values.astype('U')\n",
    "features_test = features_test.values.astype('U')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Обучим векторизатор на тренировочной части данных, переведем в вектора обе\n",
    "tf_idf_features_train = count_tf_idf.fit_transform(features_train)\n",
    "tf_idf_features_test = count_tf_idf.transform(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 логистической регрессии, кросс-валидация на обучающей выборке 0.7322415411521103\n",
      "\n",
      "f1 логистической регрессии на тестовой выборке 0.7514792899408285\n"
     ]
    }
   ],
   "source": [
    "#Логистическая регрессия\n",
    "model_lr = LogisticRegression(random_state = 12345)\n",
    "print('f1 логистической регрессии, кросс-валидация на обучающей выборке',(\n",
    "    cross_val_score(model_lr, tf_idf_features_train, target_train, cv=3, scoring = 'f1')).mean())\n",
    "model_lr.fit(tf_idf_features_train,target_train)\n",
    "predict_lr = model_lr.predict(tf_idf_features_test)\n",
    "print()\n",
    "print('f1 логистической регрессии на тестовой выборке', f1_score(predict_lr,target_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 модели дерева 0.6155757180741442\n"
     ]
    }
   ],
   "source": [
    "#Модель дерева\n",
    "model_dt = DecisionTreeClassifier(random_state = 12345, max_depth = 15)\n",
    "print('f1 модели дерева',(cross_val_score(model_dt,tf_idf_features_train, target_train, cv=3, scoring = 'f1')).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 лес деревьев 0.2479645913572804\n"
     ]
    }
   ],
   "source": [
    "#Лес деревьев\n",
    "model_rf = RandomForestClassifier(random_state = 12345, n_estimators = 2, max_depth = 10)\n",
    "print('f1 лес деревьев',(cross_val_score(model_rf,tf_idf_features_train,target_train, cv=3, scoring = 'f1')).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель линейной регрессии, после предварительной подготовки признаков (токенизация, лемматизация и очищение от не несущих смысловую нагрузку слов, показывает лучший результат метрики f1, удовлетворяющий условиям задачи. Для достижения результата соотношение трейновой к тестовой увеличил в соотношении 95% к 5% - ограничений на этот счёт в условиях не было"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 252,
    "start_time": "2021-07-16T08:17:50.739Z"
   },
   {
    "duration": 1174,
    "start_time": "2021-07-16T08:17:53.977Z"
   },
   {
    "duration": 612,
    "start_time": "2021-07-16T08:17:55.549Z"
   },
   {
    "duration": 3548,
    "start_time": "2021-07-16T08:18:50.845Z"
   },
   {
    "duration": 1137,
    "start_time": "2021-07-16T08:21:37.781Z"
   },
   {
    "duration": 567,
    "start_time": "2021-07-16T08:21:38.920Z"
   },
   {
    "duration": 3,
    "start_time": "2021-07-16T08:21:39.490Z"
   },
   {
    "duration": 3964,
    "start_time": "2021-07-16T08:21:39.495Z"
   },
   {
    "duration": 231,
    "start_time": "2021-07-16T08:21:43.461Z"
   },
   {
    "duration": 2,
    "start_time": "2021-07-16T08:21:43.694Z"
   },
   {
    "duration": 34,
    "start_time": "2021-07-16T08:21:43.697Z"
   },
   {
    "duration": 1997,
    "start_time": "2021-07-16T08:21:43.732Z"
   },
   {
    "duration": 7744,
    "start_time": "2021-07-16T08:21:45.731Z"
   },
   {
    "duration": 35155,
    "start_time": "2021-07-16T08:21:53.476Z"
   },
   {
    "duration": 13099,
    "start_time": "2021-07-16T08:22:28.632Z"
   },
   {
    "duration": 604,
    "start_time": "2021-07-16T08:22:41.733Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
